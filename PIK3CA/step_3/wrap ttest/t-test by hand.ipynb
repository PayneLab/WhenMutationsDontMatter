{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahboekweg/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import statsmodels.stats.multitest\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import gseapy as gp\n",
    "import re\n",
    "import sys \n",
    "\n",
    "import cptac\n",
    "import cptac.utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    }
   ],
   "source": [
    "en = cptac.Endometrial()\n",
    "col = cptac.Colon()\n",
    "br = cptac.Brca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_ttest(df, label_column, comparison_columns=None, alpha=.05, return_all=False, correction_method='bonferroni'):\n",
    "    try:\n",
    "        '''Verify precondition that label column exists and has exactly 2 unique values'''\n",
    "        label_values = df[label_column].unique()\n",
    "        if len(label_values) != 2:\n",
    "            print(\"Incorrectly Formatted Dataframe! Label column must have exactly 2 unique values.\")\n",
    "            return None\n",
    "        \n",
    "        '''Partition dataframe into two sets, one for each of the two unique values from the label column'''\n",
    "        partition1 = df.loc[df[label_column] == label_values[0]]\n",
    "        partition2 = df.loc[df[label_column] == label_values[1]]\n",
    "\n",
    "        '''If no comparison columns specified, use all columns except the specified labed column'''\n",
    "        if not comparison_columns:\n",
    "            comparison_columns = list(df.columns)\n",
    "            comparison_columns.remove(label_column)\n",
    "\n",
    "        '''Determine the number of real valued columns on which we will do t-tests'''\n",
    "        number_of_comparisons = len(comparison_columns)\n",
    "\n",
    "        '''Store comparisons and p-values in two arrays'''\n",
    "        comparisons = []\n",
    "        pvals = []\n",
    "        \n",
    "        '''Loop through each comparison column, perform the t-test, and record the p-val'''\n",
    "        for column in comparison_columns:\n",
    "            stat, pval = scipy.stats.ttest_ind(partition1[column].dropna(axis=0), partition2[column].dropna(axis=0))\n",
    "            comparisons.append(column)\n",
    "            pvals.append(pval)\n",
    "            \n",
    "        '''Correct for multiple testing to determine if each comparison meets the new cutoff'''\n",
    "        results = statsmodels.stats.multitest.multipletests(pvals=pvals, alpha=alpha, method=correction_method)\n",
    "        reject = results[0]\n",
    "\n",
    "        '''Format results in a pandas dataframe'''\n",
    "        results_df = pd.DataFrame(columns=['Comparison','P_Value'])\n",
    "\n",
    "        '''If return all, add all comparisons and p-values to dataframe'''\n",
    "        if return_all:\n",
    "            results_df['Comparison'] = comparisons\n",
    "            results_df['P_Value'] = pvals\n",
    "\n",
    "            '''Else only add significant comparisons'''\n",
    "        else:\n",
    "            for i in range(0, len(reject)):\n",
    "                if reject[i]:\n",
    "                    results_df = results_df.append({'Comparison':comparisons[i],'P_Value':pvals[i]}, ignore_index=True)\n",
    "\n",
    "\n",
    "        '''Sort dataframe by ascending p-value'''\n",
    "        results_df = results_df.sort_values(by='P_Value', ascending=True)\n",
    "        results_df = results_df.reset_index(drop=True)\n",
    "\n",
    "        '''If results df is not empty, return it, else return None'''\n",
    "        if len(results_df) > 0:\n",
    "            return results_df\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    except:\n",
    "        print(\"Incorrectly Formatted Dataframe!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cptac warning: In joining the somatic_mutation table, no mutations were found for the following samples, so they were filled with Wildtype_Tumor or Wildtype_Normal: 48 samples for the PIK3CA gene (/Users/hannahboekweg/anaconda3/lib/python3.7/site-packages/cptac/dataset.py, line 311)\n"
     ]
    }
   ],
   "source": [
    "mut = en.get_genotype_all_vars(\"PIK3CA\", mutation_hotspot=['E542K', 'E545K', 'H1047R'])\n",
    "prot = en.get_proteomics(tissue_type=\"tumor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = mut.join(prot)\n",
    "\n",
    "en_hotspot_df = joined[joined.Location.str.contains('E542K') | \n",
    "                    joined.Location.str.contains('E545K') |\n",
    "                    joined.Location.str.contains('H1047R')]\n",
    "\n",
    "# en_hotspot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildtype  = joined.loc[joined.Mutation == \"Wildtype_Tumor\"]\n",
    "\n",
    "endo_hotspot = en_hotspot_df.append(wildtype)\n",
    "\n",
    "prot_and_mutations = endo_hotspot.drop(columns = [\"Mutation_Status\", \"Location\"])\n",
    "# prot_and_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = prot_and_mutations[\"Mutation\"].unique()\n",
    "\n",
    "'''Partition dataframe into two sets, one for each of the two unique values from the label column'''\n",
    "partition1 = prot_and_mutations.loc[prot_and_mutations[\"Mutation\"] == label_values[0]]\n",
    "partition2 = prot_and_mutations.loc[prot_and_mutations[\"Mutation\"] == label_values[1]]\n",
    "\n",
    "'''If no comparison columns specified, use all columns except the specified labed column'''\n",
    "comparison_columns = list(prot_and_mutations.columns)\n",
    "comparison_columns.remove(\"Mutation\")\n",
    "\n",
    "number_of_comparisons = len(comparison_columns)\n",
    "\n",
    "'''Store comparisons and p-values in two arrays'''\n",
    "comparisons = []\n",
    "pvals = []\n",
    "\n",
    "'''Loop through each comparison column, perform the t-test, and record the p-val'''\n",
    "times_through = 0\n",
    "for column in comparison_columns:  \n",
    "    times_through += 1\n",
    "    if len(partition1[column].dropna(axis=0)) <= 1:\n",
    "#         comparison_columns.remove(column)\n",
    "        continue\n",
    "    elif len(partition2[column].dropna(axis=0)) <= 1:\n",
    "#         comparison_columns.remove(column)\n",
    "        continue\n",
    "    else:\n",
    "        stat, pval = scipy.stats.ttest_ind(partition1[column].dropna(axis=0), partition2[column].dropna(axis=0))\n",
    "        comparisons.append(column)\n",
    "        pvals.append(pval)\n",
    "    \n",
    "'''Correct for multiple testing to determine if each comparison meets the new cutoff'''\n",
    "results = statsmodels.stats.multitest.multipletests(pvals=pvals, alpha=.05, method='fdr_bh')\n",
    "reject = results[0]\n",
    "\n",
    "\n",
    "'''Format results in a pandas dataframe'''\n",
    "results_df = pd.DataFrame(columns=['Comparison','P_Value'])\n",
    "\n",
    "for i in range(0, len(reject)):\n",
    "    if reject[i]:\n",
    "        results_df = results_df.append({'Comparison':comparisons[i],'P_Value':pvals[i]}, ignore_index=True)\n",
    "\n",
    "\n",
    "'''Sort dataframe by ascending p-value'''\n",
    "results_df = results_df.sort_values(by='P_Value', ascending=True)\n",
    "results_df = results_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comparison</th>\n",
       "      <th>P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Comparison, P_Value]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937396811758431"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006445848058977635"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-c500d2b976894a958fbdb5bce13d55fd\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c500d2b976894a958fbdb5bce13d55fd\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c500d2b976894a958fbdb5bce13d55fd\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"url\": \"altair-data-c7bb2c404b8b0dca608311d76e2a0f94.json\", \"format\": {\"type\": \"json\"}}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"bin\": {\"step\": 0.05}, \"field\": \"p_val\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "alt.data_transformers.enable('json')\n",
    "alt.Chart(pd.DataFrame({\"p_val\":pvals})).mark_bar().encode(\n",
    "    x=alt.X(\"p_val:Q\",bin=alt.Bin(step=0.05)),\n",
    "    y=\"count()\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
