{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_data_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from functools import reduce\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cptac\n",
    "import cptac.dataframe_tools as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in source_class:\n",
    "    data_types = c.data.keys\n",
    "    # get rid of cancer name to keep source\n",
    "    # return df data_types and sources (merge on datatype, then combine cols )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medical_conditions(self, source, tissue_type=\"both\", imputed=False):\n",
    "    \"\"\"Get the medical_conditions dataframe from the specified data source.\"\"\"\n",
    "    return self._get_dataframe(\"medical_conditions\", source, tissue_type, imputed=imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(datatype = 'miRNA', source = 'washu'): #make index files\n",
    "    if datatype == 'miRNA':\n",
    "        #with open ('~/Documents/Standardized_pipeline/WashU/MicroRNA/README_miRNA') as f:\n",
    "        with open ('README_miRNA copy') as f:\n",
    "            lines = f.read()\n",
    "            print(lines)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Only the data corresponding to Case_ID in the pan-cancer data freeze are included in the Box folder.\n",
      "\n",
      "CPTAC miRNA-Seq analysis\n",
      "========================\n",
      "\n",
      "### github: <https://github.com/ding-lab/CPTAC_miRNA>\n",
      "\n",
      "### Lijun Yao lijunyao@wustl.edu\n",
      "### Pipeline developed by Sunantha Sethuraman, modified by Lijun Yao\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Processing description\n",
      "----------------------\n",
      "\n",
      "The raw data was made available as .unaln.bam files.\n",
      "\n",
      "Annotation pre-processing:\n",
      "\n",
      "Annotation information to be used in the pipeline were downloaded from\n",
      "miRBase v22 and GENCODE v29. The downloaded GTFs were converted to BED\n",
      "format files. For GENCODE, only the transcript variant labeled with the\n",
      "'Basic' tag was used since it is the predominant transcript variant.\n",
      "Annotations were limited to standard chromosomes Chr 1-22, X,Y and MT.\n",
      "\n",
      "Unaligned BAM to FASTQ:\n",
      "\n",
      "The unaligned bams were first converted to fastq.gz files by samtools bam2fq\n",
      "\n",
      "Adapter trimming:\n",
      "\n",
      "The fastq.gz files were then trimmed using TRIMMOMATIC (Bolger, A. M.,\n",
      "Lohse, M., & Usadel, B. (2014). Trimmomatic: A flexible trimmer for\n",
      "Illumina Sequence Data. Bioinformatics, btu170) with the adapter\n",
      "sequences provided in Adapters.fa. The following constraints were used\n",
      "during trimming: 1. Random 4 nucleotides at the start and end of the\n",
      "read after adapter trimming were cropped; 2. Any read with average read\n",
      "quality &lt; 30 was dropped; 3. Any read with average base quality &lt;\n",
      "20 in any sliding window of 10 bases was dropped; 4. Reads shorter than\n",
      "15 bases after processing were dropped.\n",
      "\n",
      "Quality check:\n",
      "\n",
      "FASTQC (<https://www.bioinformatics.babraham.ac.uk/projects/fastqc/>)\n",
      "was used to quality check the reads before and after trimming to ensure\n",
      "adapter removal.\n",
      "\n",
      "Alignment:\n",
      "\n",
      "The reads were aligned to the human genome (Reference GRCh38) using bwa\n",
      "aln, allowing no mismatches. For any given read up to 10 alignments were\n",
      "permitted. The aligned SAM file contains one line per read with the\n",
      "information about multiple alignments reported in that line. For\n",
      "downstream analysis purposes, it was required to have one alignment per\n",
      "line and this was accomplished using the xa2multi.pl script. The SAM\n",
      "file was then converted to a BED file and sorted.\n",
      "\n",
      "Annotation:\n",
      "\n",
      "The BED file was annotated using BEDTOOLS 'intersect' and several\n",
      "preprocessed annotation files (see annotation pre-processing above). A\n",
      "custom python script (mirna\\_annotation.py) was used to handle multiple\n",
      "annotations and multi-mapping of the reads to obtain one unique mapping\n",
      "per read and one unique annotation per mapping.\n",
      "\n",
      "Multiple annotations were resolved in the order of priority:\n",
      "\n",
      "'miRNA', 'miRNA\\_primary\\_transcript', 'tRNA', 'rRNA', 'sRNA', 'snRNA',\n",
      "'snoRNA', 'scaRNA', 'scRNA', 'ribozyme', 'vaultRNA', 'Mt\\_tRNA',\n",
      "'Mt\\_rRNA', 'protein\\_coding','3prime\\_overlapping\\_ncRNA',\n",
      "'bidirectional\\_promoter\\_lncRNA', 'lincRNA','macro\\_lncRNA',\n",
      "'misc\\_RNA', 'non\\_coding','antisense', 'sense\\_intronic',\n",
      "'sense\\_overlapping', 'IG\\_C\\_gene', 'IG\\_D\\_gene', 'IG\\_J\\_gene',\n",
      "'IG\\_V\\_gene', 'TR\\_C\\_gene', 'TR\\_D\\_gene', 'TR\\_J\\_gene',\n",
      "'TR\\_V\\_gene', 'IG\\_C\\_pseudogene','IG\\_J\\_pseudogene',\n",
      "'IG\\_V\\_pseudogene', 'IG\\_pseudogene', 'TR\\_J\\_pseudogene',\n",
      "'TR\\_V\\_pseudogene', 'rRNA\\_pseudogene', 'processed\\_transcript',\n",
      "'pseudogene', 'polymorphic\\_pseudogene', 'processed\\_pseudogene',\n",
      "'transcribed\\_processed\\_pseudogene',\n",
      "'transcribed\\_unitary\\_pseudogene',\n",
      "'transcribed\\_unprocessed\\_pseudogene',\n",
      "'translated\\_processed\\_pseudogene', 'unitary\\_pseudogene',\n",
      "'unprocessed\\_pseudogene', 'TEC','unannotated'\n",
      "\n",
      "Since mature miRNAs are processed from precursor miRNAs (referred above\n",
      "as 'miRNA\\_primary\\_transcript'), most of the reads mapping to mature\n",
      "miRNAs also map to precursor miRNAs and vice-versa. The priorities were\n",
      "assigned by overlap length, allowing a 3 nt additional advantage to\n",
      "mature miRNAs. This advantage allow to correct for processing errors\n",
      "(biological and sequencing based) and the number 3 was empirically\n",
      "determined.\n",
      "\n",
      "Multimapping was resolved based on the same order of priority as above.\n",
      "Additionally, multi-maps within the same annotation group were assigned\n",
      "randomly to one location.\n",
      "\n",
      "Couting:\n",
      "\n",
      "For each mature miRNA and precursor miRNA, the number of reads were\n",
      "counted. The raw counts were then converted to TPM (Transcripts per\n",
      "million) values using (raw\\_counts)\\*10e6/(total\\_counts), where\n",
      "total\\_counts = total number of reads aligned to all miRNAs (mature +\n",
      "precursor). It is important to note that TPM was not calculated as a\n",
      "function of library size. The counts were summed for each precursor\n",
      "miRNA (precursor + isoforms) and is reported as one file.\n",
      "\n",
      "Output:\n",
      "\n",
      "For each sample, three output files are provided with the following\n",
      "suffixes: \".mature.txt\", \".precursor.txt\" and \".total.txt\" which contain\n",
      "information on mature miRNA counts, precursor miRNA counts and total\n",
      "miRNA counts, respectively.\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Sample nomenclature\n",
      "-------------------\n",
      "\n",
      "The samples follow the naming system \"\\[SubjectID\\].\\[T or\n",
      "A\\].type.txt\", where T or A specifies whether it is a tumor or a\n",
      "tumor\\_normal sample (for example: C3N-01521.T.mature.txt). Type refers\n",
      "to mature, precursor or total.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        \r"
     ]
    }
   ],
   "source": [
    "g = cptac.Gbm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the dataframes contained in this dataset:\n",
      "\tacetylproteomics\n",
      "\t\tDimensions: (109, 18767)\n",
      "\tcircular_RNA\n",
      "\t\tDimensions: (99, 3670)\n",
      "\tclinical\n",
      "\t\tDimensions: (115, 29)\n",
      "\tCNV\n",
      "\t\tDimensions: (98, 19907)\n",
      "\tderived_molecular\n",
      "\t\tDimensions: (109, 19)\n",
      "\texperimental_design\n",
      "\t\tDimensions: (115, 7)\n",
      "\tgene_fusion\n",
      "\t\tDimensions: (2090, 8)\n",
      "\tlipidomics\n",
      "\t\tDimensions: (88, 582)\n",
      "\tmetabolomics\n",
      "\t\tDimensions: (87, 134)\n",
      "\tmiRNA\n",
      "\t\tDimensions: (106, 2883)\n",
      "\tphosphoproteomics\n",
      "\t\tDimensions: (109, 101266)\n",
      "\tproteomics\n",
      "\t\tDimensions: (109, 11141)\n",
      "\tsomatic_mutation\n",
      "\t\tDimensions: (5774, 3)\n",
      "\ttranscriptomics\n",
      "\t\tDimensions: (108, 60483)\n"
     ]
    }
   ],
   "source": [
    "g.list_data() #look at code or docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sources():\n",
    "    ds = {'transcriptomics': 'bcm, broad, washu',\n",
    "          'proteomics': 'cdap, umich', \n",
    "          'phosphoproteomics':  'cdap, umich',\n",
    "          'miRNA': 'washu',\n",
    "          'deconvolution': 'washu',\n",
    "          'tumor_purity': 'washu'}\n",
    "    \n",
    "    print(' transcriptomics: bcm, broad, washu', '\\n',\n",
    "          'proteomics: cdap, umich', '\\n',\n",
    "          'phosphoproteomics: cdap, umich','\\n',\n",
    "          'miRNA: washu', '\\n',\n",
    "          'deconvolution: washu', '\\n',\n",
    "          'tumor_purity: washu', '\\n')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sources():\n",
    "    \"\"\"List all available sources.\"\"\"\n",
    "\n",
    "    dataset_list_url = \"https://byu.box.com/shared/static/5vwsvgu8fyzao0pb7rx8lt26huofcdax.tsv\" # url to file i make\n",
    "\n",
    "    try:\n",
    "        dataset_list_text = _download_text(dataset_list_url)\n",
    "    except NoInternetError:\n",
    "        raise NoInternetError(\"Insufficient internet to download available dataset info. Check your internet connection.\") from None\n",
    "\n",
    "    return pd.read_csv(io.StringIO(dataset_list_text), sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " transcriptomics: bcm, broad, washu \n",
      " proteomics: cdap, umich \n",
      " phosphoproteomics: cdap, umich \n",
      " miRNA: washu \n",
      " deconvolution: washu \n",
      " tumor_purity: washu \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNV: \n",
    "ciRNA baylor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
